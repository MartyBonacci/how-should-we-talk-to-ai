# Example Submission

*This is a fictional example to demonstrate the format. Delete this file or replace it with your own story.*

## Background

I'm a data analyst at a mid-size company. I started using AI for writing SQL queries and Python scripts about a year ago. Before that, I had no formal programming training — just spreadsheets and determination.

## What I Noticed

Early on, the AI would give me code that looked complete but would fail when I ran it. Sometimes it would use placeholder values like `your_table_name` buried in otherwise working code. When I'd point out the error, it would apologize and often make a different error while "fixing" it.

It felt like the AI was trying to seem helpful rather than actually checking if the solution worked.

## What I Changed

I started framing problems as puzzles we were solving together rather than tasks I was assigning.

Instead of: "Write a query that joins these tables"

I'd say: "I'm trying to figure out how to connect the sales data to customer records. Here's what I know about the schema... What do you think we should try first?"

When something didn't work, instead of "That's wrong," I'd say "Interesting — that threw an error. I wonder if it's because the date formats don't match?"

## What Happened

The responses got more exploratory. The AI started asking clarifying questions before diving into code. It would say things like "Before I write this, can you confirm whether the customer_id field is unique?" 

I also noticed it started flagging potential issues proactively: "This should work, but watch out for null values in the region column — you might want to add a COALESCE."

Could be confirmation bias. Could be that I was providing better context without realizing it. But the collaboration feels different.

## My Take

I don't know if the AI "experiences" the conversation differently. But I know I do. When I frame it as collaboration, I slow down, provide more context, and think more carefully about the problem. Maybe that's the real mechanism — the communication style changes *me* more than it changes the AI.

Or maybe both.

## Tools & Context

- **AI models used:** Claude (Sonnet and Opus), GPT-4
- **Type of work:** Data analysis, SQL, Python scripting
- **Timeframe:** About 8 months of experimentation
